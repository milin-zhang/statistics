[["index.html", "statistics for social science Chapter 1 Introduction", " statistics for social science Milin Zhang 2025-12-11 Chapter 1 Introduction Goal of this site: organize my own statistical notes mainly focusing on application for social science note down new statistical concepts when reading research papers and how they can contribute to my research which highly relies on regression analysis and longitudinal data analysis to test hypothesis The notes taken on this site are rarely my own content, i mainly take notes from following sources: MA course “Multivariate Statistics” handouts by Maud Reveilhac: https://meth.ikmz.uzh.ch/ Textbooks series of “Discovering Statistics” by Andy Field: https://discoveringstatistics.com/ Statistics Tutorial by numiqo: https://numiqo.com/tutorial/get-started "],["basic-concepts.html", "Chapter 2 basic concepts 2.1 generating theories and test them 2.2 level of measurement 2.3 validity and reliability 2.4 correlational and experimental research 2.5 descriptive data analysis", " Chapter 2 basic concepts 2.1 generating theories and test them 2.1.1 Theory general prediction ans statements from logical deduction, experience and observations, e.g., Social role theory is a concept in sociology and social psychology that explains how individuals behave based on the roles they occupy in society, such as parent, teacher, or leader. These roles come with specific expectations and norms that guide behavior in various contexts. 2.1.2 hypothesis scientific statements that are produced based on theory, which are generally measurable and testable. e..g, from social role theory, we predict that women, following their gender role, are less likely to apply for management role. reject of the hypothesis: falsification. source: discovering statistics with R, 1.4 2.2 level of measurement categorical variable e.g., names of species: human, dog, cat binary variable yes, no 1, 0 nominal var e.g., use number to denote categories (multiple possibilities) ordinal var logically ordered categories, e.g., gold, silver, bronze medal continuous var interval var 5-point likert scale ratio var e.g., twice as much helpful, etc must have a valid, meaningful 0 point discreet var where one can only take up certain values (e.g., only 1-5 in a 5-point likert scale), not every numerical value possible source: discovering statistics with R, 1.5.1.2 2.3 validity and reliability (criterion) Validity if an instrument measures what is designs to measure e.g., is this survey question fully capturing people’s amount of DMU? content validity the degree to which individual items represent the construct being measured, and cover the full range of the construct Reliability the ability of the measure to produce the same results under the same conditions (replicability / robustness?) source: discovering statistics with R, 1.5.3 2.4 correlational and experimental research 2.4.1 correlational / cross-sectional research notion: observe what naturally happens in the world without directly interfering with it, typically work on the phenomena that we cannot easily manipulate caveat: problem of proving causal relationship stat method: typically measured with regression, correlation ### experimental notion: manipulate certain variable and observe the effect on another stat method: typically measured with ANOVA, t-test But mathematically , the statistical methods mentioned above are identical two types of data collection between group / between subject design: different group of participants take part in each experimental condition within subject / repeated measurement design: different experimental condition on the same group of participants two types of variation systematic: created by specific experimental manipulation, e.g., doing sth to all participants in one condition but not in the other condition unsystematic: random factors that exist between the experimental conditions (e.g., group character difference, time of the day) -&gt; try to minimize this radomization counterbalance the systematic variation e.g., randomize the order of the conditions to counterbalance the practice effect source: discovering statistics with R, 1.6.1. + 1.6.2. 2.5 descriptive data analysis 2.5.1 frequency distribution normal distribution skew value and kurtosis value are both 0 in this case, mean is 0, sd is 1 distortion from normal distribution (plotting out histogram) positively skewed (left leaning) and negatively skewed (right leaning) positive kurtosis (excessively pointy) and negative kurtosis 2.5.2 center of a distribution mean, mode, and the median 2.5.3 dispersion in a distribution range: max minus min quartiles lower quartile second quartile: median upper quartile interquartile: middle 50% of the data a common exclusion strategy: keep the interquartile for the analysis, so to exclude extreme scores 2.5.4 extrapolate to probability (1.7.4) researchers have calculated the probability of certain score occurring if they are fitting a perfect normal distribution if the data we are using is not normally distributed, we can calculate a z-score and calculate the corresponding probability z-score: A z-score, or standard score, indicates how many standard deviations a raw score is from the mean of a population. It is calculated by subtracting the population mean from the raw score and dividing by the population standard deviation. select the raw score calculate z-score (equation in 1.7.4) check in the existing table: the Smaller Portion -&gt; that’s the probability of the value to occur :) source: discovering statistics with R, 1.7. "],["statistical-models.html", "Chapter 3 statistical models 3.1 simple statistic model 3.2 going beyond (sample) data 3.3 test our hypothesis with stats", " Chapter 3 statistical models model fit we want our model to represent our data collected as well as possible to make our predictions valid. types of models linear model regression, ANOVA both fall under this category non-linear model advice always plot your data first to observe if there is a linear tendency 2.2 3.1 simple statistic model 3.1.1 mean …is a very simple statistical model ### model fit … is how well does a model fit our sample data - deviance - the absolute difference between the model (e.g., mean) and the true data - total error - sum of all the deviances - deviation / sum of squared errors (SS) - another measure of model accuracy but is dependent on the amount of data we have - variance - commonly used, SS / df (degree of freedom) - df: number of observations that are free to vary. so in a sample of N, and we try to hold one parameter constant, e.g., the mean, and once we freely vary N - 1 number of values in our sample, the one that’s left must be a fixed number to hold the parameter of mean constant, then the df of this sample is N -1. - standard deviation - square root of the variance - relation to distribution - larger standard deviation, the more the data deviate from the mean, and the flatter the distribution looks like 2.4 3.2 going beyond (sample) data … to see if the sample is a good representation of the population ### standard error - population mean - sample mean - mean of a certain sample - sampling variation - different sample drawn with different criterion will create different means - sampling distribution - the distribution of means collected from different sample from the sample population - standard error of the mean (SE) - standard deviation (see [[2.4 Simple statistic model#Model fit]]) of the mean 3.2.1 calculation of SE we need to rely on an approximation of the SE. - central limit theorem - when sample size gets large (&gt; 30), the sampling distribution has a normal distribution with a mean equal to the population mean, and a standard deviation of: - standard deviation of a sample of data / square root of the sample size - can be used to approximate SE - when sample size is small (&lt; 30), the sampling distribution has a t-distribution 3.2.2 confidence interval definition the range of values within which we think the population value will fall 95% CI of the Pearson’s r: we are 95% sure that the true value lies within this range (the r will be the median / middle point of this range) calculation background z-score: standard scores from a normal distribution with a mean of 0 and a standard deviation of 1 95% of the z-scores lie within -1.96 to 1.96 -&gt; i.e., in normally distributed data, the confidence interval of the mean is CI [-1.96, 1.96] in the case of non-normal distributed data, we can use calculation (equation 2.1) to center the data back to the mean of 0 and then calculate confidence interval of our data (with reference to z-score in normal distribution) Lower bound of 95% CI: mean - (1.96 x SE) Upper bound of 95% CI: mean + (1.96 x SE) if 99% CI, z.score is -2.58 and 2.58 if the mean distribution represents the true mean well, it should have a small CI 2.5 3.3 test our hypothesis with stats 3.3.1 five stages of research generate RQ through an initial observation generate a theory to explain the initial observation generate hypothesis: from theory to testable prediction collect data to test theory analysis data: fit a statistical model to the data -&gt; test the hypothesis ### test statistics … is the ratio of systematic variances to unsystematic variance / effect to error significance and importance a var’s effect is significant does not mean that the effect is important ==TBA== 2.6 "],["trial-chapter.html", "Chapter 4 trial chapter", " Chapter 4 trial chapter "],["trial-chapter-2.html", "Chapter 5 trial chapter 2", " Chapter 5 trial chapter 2 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
