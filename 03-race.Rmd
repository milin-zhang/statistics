# statistical models
- model fit
we want our model to represent our data collected as well as possible to make our predictions valid.
- types of models
  - linear model
  	- regression, ANOVA both fall under this category
  - non-linear model
- advice
always plot your data first to observe if there is a linear tendency

2.2

## simple statistic model
### mean
...is a very simple statistical model
### model fit
... is how well does a model fit our sample data
- deviance
	- the absolute difference between the model (e.g., mean) and the true data
- total error 
	- sum of all the deviances
- deviation / sum of squared errors (SS)
	- another measure of model accuracy but is dependent on the amount of data we have
- variance
	- commonly used, SS / df (degree of freedom)
		- df: number of observations that are free to vary. so in a sample of N, and we try to hold one parameter constant, e.g., the mean, and once we freely vary N - 1 number of values in our sample, the one that's left must be a fixed number to hold the parameter of mean constant, then the df of this sample is N -1.
- standard deviation
	- square root of the variance
	- relation to distribution
		- larger standard deviation, the more the data deviate from the mean, and the flatter the distribution looks like

2.4

## going beyond (sample) data
... to see if the sample is a good representation of the population
### standard error
- population mean
- sample mean
	- mean of a certain sample
- sampling variation
	- different sample drawn with different criterion will create different means
- sampling distribution
	- the distribution of means collected from different sample from the sample population
- standard error of the mean (SE)
	- standard deviation (see [[2.4 Simple statistic model#Model fit]]) of the mean 

### calculation of SE
we need to rely on an approximation of the SE.
- central limit theorem
	- when sample size gets large (> 30), the sampling distribution has a normal distribution with a mean equal to the population mean, and a standard deviation of:
		- standard deviation of a sample of data / square root of the sample size
			- can be used to approximate SE
	- when sample size is small (< 30), the sampling distribution has a t-distribution

### confidence interval
- definition
	- the range of values within which we think the population value will fall
		- 95% CI of the Pearson's r: we are 95% sure that the true value lies within this range (the r will be the median / middle point of this range)
- calculation
	- background
		- z-score: standard scores from a normal distribution with a mean of 0 and a standard deviation of 1
			- 95% of the z-scores lie within -1.96 to 1.96 -> i.e., in normally distributed data, the confidence interval of the mean is CI [-1.96, 1.96]
		- in the case of non-normal distributed data, we can use calculation (equation 2.1) to center the data back to the mean of 0 and then calculate confidence interval of our data (with reference to z-score in normal distribution)
			- Lower bound of 95% CI: mean - (1.96 x SE)
			- Upper bound of 95% CI: mean + (1.96 x SE)
				- if 99% CI, z.score is -2.58 and 2.58
			- if the mean distribution represents the true mean well, it should have a small CI

2.5

## test our hypothesis with stats
### five stages of research
1. generate RQ through an initial observation
2. generate a theory to explain the initial observation
3. generate hypothesis: from theory to testable prediction
4. collect data to test theory
5. analysis data: fit a statistical model to the data -> test the hypothesis
### test statistics
... is the ratio of systematic variances to unsystematic variance / effect to error
- significance and importance
	- a var's effect is significant does not mean that the effect is important ==TBA==
2.6